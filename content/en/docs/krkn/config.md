---
title: Krkn Config Explanations
description: Krkn config field explanations
weight: 1
---

# Config
Set the scenarios to inject and the tunings like duration to wait between each scenario in the config file located at [config/config.yaml](https://github.com/redhat-chaos/krkn/blob/main/config/config.yaml).

**NOTE**: [config](https://github.com/redhat-chaos/krkn/blob/main/config/config_performance.yaml) can be used if leveraging the [automated way](https://github.com/redhat-chaos/krkn#setting-up-infrastructure-dependencies) to install the infrastructure pieces.

Config components: 
* [Kraken](#kraken)
* [Cerberus](#cerberus)
* [Performance Monitoring](#performance-monitoring)
* [ElasticSearch](#elastic)
* [Tunings](#tunings)
* [Telemetry](#telemetry)
* [Health Checks](#health-checks)
* [Virt Checks](#virt-checks)

## Kraken 
This section defines scenarios and specific data to the chaos run 

### Distribution
The distribution is now automatically set based on some verification points. Depending on which distribution, either **openshift** or **kubernetes** other parameters will be automatically set. 
The prometheus url/route and bearer token are automatically obtained in case of OpenShift, please be sure to set it when the distribution is Kubernetes.


### Exit on failure
**exit_on_failure**:  Exit when a post action check or cerberus run fails

### Publish kraken status
Refer to [signal.md](signal.md) for more details

**publish_kraken_status**: Can be accessed at http://0.0.0.0:8081 (or what signal_address and port you set in signal address section)

**signal_state**: State you want krkn to start at; will wait for the RUN signal to start running a chaos iteration. When set to PAUSE before running the scenarios

**signal_address**: Address to listen/post the signal state to

**port**: port to listen/post the signal state to


### Chaos Scenarios 

**chaos_scenarios**: List of different types of chaos scenarios you want to run with paths to their specific yaml file configurations.

Currently the scenarios are run one after another (in sequence) and will exit if one of the scenarios fail, without moving onto the next one. You can find more details on each scenario under the [Scenario](../scenarios/) folder.  

Chaos scenario types: 
- pod_disruption_scenarios
- container_scenarios
- hog_scenarios
- node_scenarios
- time_scenarios
- cluster_shut_down_scenarios
- namespace_scenarios
- zone_outages
- application_outages
- pvc_scenarios
- network_chaos
- pod_network_scenarios
- service_disruption_scenarios
- service_hijacking_scenarios
- syn_flood_scenarios


## Cerberus 
Parameters to set for enabling of cerberus checks at the end of each executed scenario. The given url will pinged after the scenario and post action check have been completed for each scenario and iteration. Read more about what cerberus is [here](../cerberus/_index.md)

**cerberus_enabled**: Enable it when cerberus is previously installed

**cerberus_url**: When cerberus_enabled is set to True, provide the url where cerberus publishes go/no-go signal

**check_applicaton_routes**:  When enabled will look for application unavailability using the routes specified in the cerberus config and fails the run


## Performance Monitoring
**prometheus_url**:  The prometheus url/route is automatically obtained in case of OpenShift, please set it when the distribution is Kubernetes.

**prometheus_bearer_token**: The bearer token is automatically obtained in case of OpenShift, please set it when the distribution is Kubernetes. This is needed to authenticate with prometheus.

**uuid**: Uuid for the run, a new random one is generated by default if not set. Each chaos run should have its own unique UUID

**enable_alerts**: True or False; Runs the queries specified in the alert profile and displays the info or exits 1 when severity=error

**enable_metrics**: True or False, capture metrics defined by the metrics profile

**alert_profile**: Path or URL to alert profile with the prometheus queries, see a sample of an [alerts file](https://github.com/tsebastiani/krkn/blob/main/config/alerts.yaml) of some preconfigured alerts we have set up and more documentation around it [here](SLOs_validation.md#alert-profile)

**metrics_profile**: Path or URL to metrics profile with the prometheus queries to capture certain metrics on, see more details around [metrics](SLOs_validation.md#metrics-profile) on its documentation page

**check_critical_alerts**: True or False; When enabled will check prometheus for critical alerts firing post chaos. Read more about this functionality in [SLOs validation](SLOs_validation.md#checking-for-critical-alerts-post-chaos)


## Elastic
We have enabled the ability to store telemetry, metrics and alerts into ElasticSearch based on the below keys and values. 

**enable_elastic**: True or False; If true, the telemetry data will be stored in the telemetry_index defined below. Based on if value of performance_monitoring.enable_alerts and performance_monitoring.enable_metrics are true or false, alerts and metrics will be saved in addition to each of the indexes

**verify_certs**: True or False

**elastic_url**: The url of the ElasticeSearch where you want to store data

**username**: ElasticSearch username 

**password**: ElasticSearch password 

**metrics_index**: ElasticSearch index where you want to store the metrics details, the alerts captured are defined from the performance_monitoring.metrics_profile variable and can be captured based on value of performance_monitoring.enable_alenable_metricserts

**alerts_index**: ElasticSearch index where you want to store the alert details, the alerts captured are defined from the performance_monitoring.alert_profile variable and can be captured based on value of performance_monitoring.enable_alerts

**telemetry_index**: ElasticSearch index where you want to store the telemetry details 


## Tunings
**wait_duration**: Duration to wait between each chaos scenario

**iterations**: Number of times to execute the scenarios

**daemon_mode**: True or False; If true, iterations are set to infinity which means that the krkn will cause chaos forever and number of iterations is ignored

## Telemetry
More details on the data captured in the telmetry and how to set up your own telemetry data storage can be found [here](telemetry.md)

**enabled**: True or False, enable/disables the telemetry collection feature

**api_url**: https://ulnmf9xv7j.execute-api.us-west-2.amazonaws.com/production #telemetry service endpoint

**username**: Telemetry service username

**password**: Telemetry service password

**prometheus_backup**: True or False, enables/disables prometheus data collection

**prometheus_namespace**: Namespace where prometheus is deployed, only needed if distribution is kubernetes

**prometheus_container_name**: Name of the prometheus container name, only needed if distribution is kubernetes

**prometheus_pod_name**: Name of the prometheus pod, only needed if distribution is kubernetes

**full_prometheus_backup**: True or False, if is set to False only the /prometheus/wal folder will be downloaded.

**backup_threads**: Number of telemetry download/upload threads, default is 5

**archive_path**: Local path where the archive files will be temporarly stored, default is `/tmp`

**max_retries**: Maximum number of upload retries (if 0 will retry forever), defaulted to 0

**run_tag**: If set, this will be appended to the run folder in the bucket (useful to group the runs)

**archive_size**: The size of the prometheus data archive size in KB. The lower the size of archive is the higher the number of archive files will be produced and uploaded (and processed by backup_threads simultaneously). For unstable/slow connection is better to keep this value low increasing the number of backup_threads, in this way, on upload failure, the retry will happen only on the failed chunk without affecting the whole upload.

**telemetry_group**: If set will archive the telemetry in the S3 bucket on a folder named after the value, otherwise will use "default"

**logs_backup**: True

**logs_filter_patterns**: Way to filter out certain times from the logs
```
        - "(\\w{3}\\s\\d{1,2}\\s\\d{2}:\\d{2}:\\d{2}\\.\\d+).+"         # Sep 9 11:20:36.123425532
        - "kinit (\\d+/\\d+/\\d+\\s\\d{2}:\\d{2}:\\d{2})\\s+"          # kinit 2023/09/15 11:20:36 log
        - "(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z).+"      # 2023-09-15T11:20:36.123425532Z log
```
**oc_cli_path**: Optional, if not specified will be search in $PATH, default is `/usr/bin/oc` 

**events_backup**: True or False, this will capture events that occured during the chaos run. Will be saved to {archive_path}/events.json

## Health Checks                                              
Utilizing health check endpoints to observe application behavior during chaos injection, see more details about how this works and different ways to configure [here](health-checks.md)

**interval**: Interval in seconds to perform health checks, default value is 2 seconds

**config**: Provide list of health check configurations for applications

 - **url**: Provide application endpoint

   **bearer_token**: Bearer token for authentication if any

   **auth**: Provide authentication credentials (username , password) in tuple format if any, ex:("admin","secretpassword")
   
   **exit_on_failure**: If value is True exits when health check failed for application, values can be True/False

## Virt Checks                                              
Utilizing kube virt checks observe VMI's ssh connection behavior during chaos injection, see more details about how this works and different ways to configure [here](virt-checks.md)

**interval**: Interval in seconds to perform virt checks, default value is 2 seconds

**namespace**: VMI Namespace, needs to be set or checks won't be run

**name**: Provided VMI regex name to match on; optional, if left blank will find all names in namespace

**only_failures**: Boolean of whether to show all VMI's failures and successful ssh connection (False), or only failure status' (True)

**disconnected**: Boolean of how to try to connect to the VMIs; if True will use the ip_address to try ssh from within a node, if false will use the name and uses virtctl to try to connect; Default is False


## Sample Config file

```yaml 
kraken:
    kubeconfig_path: ~/.kube/config                     # Path to kubeconfig
    exit_on_failure: False                                 # Exit when a post action scenario fails
    publish_kraken_status: True                            # Can be accessed at http://0.0.0.0:8081
    signal_state: RUN                                      # Will wait for the RUN signal when set to PAUSE before running the scenarios, refer docs/signal.md for more details
    signal_address: 0.0.0.0                                # Signal listening address
    port: 8081                                             # Signal port
    chaos_scenarios:
        # List of policies/chaos scenarios to load
        - hog_scenarios:
            - scenarios/kube/cpu-hog.yml
            - scenarios/kube/memory-hog.yml
            - scenarios/kube/io-hog.yml
        - application_outages_scenarios:
            - scenarios/openshift/app_outage.yaml
        - container_scenarios:                             # List of chaos pod scenarios to load
            - scenarios/openshift/container_etcd.yml
        - pod_network_scenarios:
              - scenarios/openshift/network_chaos_ingress.yml
              - scenarios/openshift/pod_network_outage.yml
        - pod_disruption_scenarios:
            - scenarios/openshift/etcd.yml
            - scenarios/openshift/regex_openshift_pod_kill.yml
            - scenarios/openshift/prom_kill.yml
            - scenarios/openshift/openshift-apiserver.yml
            - scenarios/openshift/openshift-kube-apiserver.yml
        - node_scenarios:                                  # List of chaos node scenarios to load
            - scenarios/openshift/aws_node_scenarios.yml
            - scenarios/openshift/vmware_node_scenarios.yml
            - scenarios/openshift/ibmcloud_node_scenarios.yml
        - time_scenarios:                                  # List of chaos time scenarios to load
            - scenarios/openshift/time_scenarios_example.yml
        - cluster_shut_down_scenarios:
            - scenarios/openshift/cluster_shut_down_scenario.yml
        - service_disruption_scenarios:
             - scenarios/openshift/regex_namespace.yaml
             - scenarios/openshift/ingress_namespace.yaml
        - zone_outages_scenarios:
            - scenarios/openshift/zone_outage.yaml
        - pvc_scenarios:
            - scenarios/openshift/pvc_scenario.yaml
        - network_chaos_scenarios:
            - scenarios/openshift/network_chaos.yaml
        - service_hijacking_scenarios:
              - scenarios/kube/service_hijacking.yaml
        - syn_flood_scenarios:
              - scenarios/kube/syn_flood.yaml

cerberus:
    cerberus_enabled: False                                # Enable it when cerberus is previously installed
    cerberus_url:                                          # When cerberus_enabled is set to True, provide the url where cerberus publishes go/no-go signal
    check_applicaton_routes: False                         # When enabled will look for application unavailability using the routes specified in the cerberus config and fails the run

performance_monitoring:
    deploy_dashboards: False                              # Install a mutable grafana and load the performance dashboards. Enable this only when running on OpenShift
    repo: "https://github.com/cloud-bulldozer/performance-dashboards.git"
    prometheus_url: ''                                      # The prometheus url/route is automatically obtained in case of OpenShift, please set it when the distribution is Kubernetes.
    prometheus_bearer_token:                              # The bearer token is automatically obtained in case of OpenShift, please set it when the distribution is Kubernetes. This is needed to authenticate with prometheus.
    uuid:                                                 # uuid for the run is generated by default if not set
    enable_alerts: False                                  # Runs the queries specified in the alert profile and displays the info or exits 1 when severity=error
    enable_metrics: False
    alert_profile: config/alerts.yaml                          # Path or URL to alert profile with the prometheus queries
    metrics_profile: config/metrics-report.yaml
    check_critical_alerts: False                          # When enabled will check prometheus for critical alerts firing post chaos
elastic:
    enable_elastic: False
    verify_certs: False
    elastic_url: ""                                         # To track results in elasticsearch, give url to server here; will post telemetry details when url and index not blank
    elastic_port: 32766
    username: "elastic"
    password: "test"
    metrics_index: "krkn-metrics"
    alerts_index: "krkn-alerts"
    telemetry_index: "krkn-telemetry"

tunings:
    wait_duration: 60                                      # Duration to wait between each chaos scenario
    iterations: 1                                          # Number of times to execute the scenarios
    daemon_mode: False                                     # Iterations are set to infinity which means that the kraken will cause chaos forever
telemetry:
    enabled: False                                           # enable/disables the telemetry collection feature
    api_url: https://ulnmf9xv7j.execute-api.us-west-2.amazonaws.com/production #telemetry service endpoint
    username: username                                      # telemetry service username
    password: password                                    # telemetry service password
    prometheus_backup: True                                 # enables/disables prometheus data collection
    prometheus_namespace: ""                                # namespace where prometheus is deployed (if distribution is kubernetes)
    prometheus_container_name: ""                           # name of the prometheus container name (if distribution is kubernetes)
    prometheus_pod_name: ""                                 # name of the prometheus pod (if distribution is kubernetes)
    full_prometheus_backup: False                           # if is set to False only the /prometheus/wal folder will be downloaded.
    backup_threads: 5                                       # number of telemetry download/upload threads
    archive_path: /tmp                                      # local path where the archive files will be temporarly stored
    max_retries: 0                                          # maximum number of upload retries (if 0 will retry forever)
    run_tag: ''                                             # if set, this will be appended to the run folder in the bucket (useful to group the runs)
    archive_size: 500000
    telemetry_group: ''                                     # if set will archive the telemetry in the S3 bucket on a folder named after the value, otherwise will use "default"
    # the size of the prometheus data archive size in KB. The lower the size of archive is
                                                            # the higher the number of archive files will be produced and uploaded (and processed by backup_threads
                                                            # simultaneously).
                                                            # For unstable/slow connection is better to keep this value low
                                                            # increasing the number of backup_threads, in this way, on upload failure, the retry will happen only on the
                                                            # failed chunk without affecting the whole upload.
    logs_backup: True
    logs_filter_patterns:
     - "(\\w{3}\\s\\d{1,2}\\s\\d{2}:\\d{2}:\\d{2}\\.\\d+).+"         # Sep 9 11:20:36.123425532
     - "kinit (\\d+/\\d+/\\d+\\s\\d{2}:\\d{2}:\\d{2})\\s+"          # kinit 2023/09/15 11:20:36 log
     - "(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z).+"      # 2023-09-15T11:20:36.123425532Z log
    oc_cli_path: /usr/bin/oc                                # optional, if not specified will be search in $PATH
    events_backup: True                                     # enables/disables cluster events collection

health_checks:                                              # Utilizing health check endpoints to observe application behavior during chaos injection.
    interval:                                               # Interval in seconds to perform health checks, default value is 2 seconds
    config:                                                 # Provide list of health check configurations for applications
        - url:                                              # Provide application endpoint
          bearer_token:                                     # Bearer token for authentication if any
          auth:                                             # Provide authentication credentials (username , password) in tuple format if any, ex:("admin","secretpassword")
          exit_on_failure:                                  # If value is True exits when health check failed for application, values can be True/False
kubevirt_checks:                                            # Utilizing virt check endpoints to observe ssh ability to VMI's during chaos injection.
    interval: 2                                             # Interval in seconds to perform virt checks, default value is 2 seconds
    namespace:                                              # Namespace where to find VMI's
    name:                                                   # Regex Name style of VMI's to watch; optional, if left blank will find all names in namespace
    only_failures: False                                    # Boolean of whether to show all VMI's failures and successful ssh connection (False), or only failure status' (True) 
```